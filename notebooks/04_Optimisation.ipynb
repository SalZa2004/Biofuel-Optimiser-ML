{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d647d3b",
   "metadata": {},
   "source": [
    "## Molecule Generation using Cetane Number (CN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d090971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH updated: ['/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/salvina2004/biofuel-ml/torchdrug_env/lib/python3.10/site-packages', '/home/salvina2004/biofuel-ml', '/home/salvina2004/biofuel-ml/src', '/home/salvina2004/biofuel-ml', '/home/salvina2004/biofuel-ml', '/home/salvina2004/biofuel-ml/src', '/home/salvina2004/biofuel-ml', '/home/salvina2004/biofuel-ml', '/home/salvina2004/biofuel-ml/src']\n",
      "Using device: cuda\n",
      "\n",
      "==============================\n",
      "     CN OPTIMIZATION START    \n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ./zinc_data/250k_rndm_zinc_drugs_clean_3.csv:  50%|█████     | 249456/498911 [00:01<00:01, 156342.09it/s]\n",
      "Constructing molecules from SMILES: 100%|██████████| 249455/249455 [03:52<00:00, 1074.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:56:39   Preprocess training set\n",
      "23:56:39   {'batch_size': 8,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': (0,),\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 10,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'capturable': False,\n",
      "               'class': 'optim.Adam',\n",
      "               'differentiable': False,\n",
      "               'eps': 1e-08,\n",
      "               'foreach': None,\n",
      "               'fused': None,\n",
      "               'lr': 1e-05,\n",
      "               'maximize': False,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'agent_update_interval': 3,\n",
      "          'atom_types': [6, 7, 8, 9, 15, 16, 17, 35, 53],\n",
      "          'baseline_momentum': 0.9,\n",
      "          'class': 'tasks.GCPNGeneration',\n",
      "          'criterion': 'ppo',\n",
      "          'gamma': 0.9,\n",
      "          'hidden_dim_mlp': 128,\n",
      "          'max_edge_unroll': 12,\n",
      "          'max_node': 38,\n",
      "          'model': {'activation': 'relu',\n",
      "                    'batch_norm': False,\n",
      "                    'class': 'models.RGCN',\n",
      "                    'concat_hidden': False,\n",
      "                    'edge_input_dim': None,\n",
      "                    'hidden_dims': [256, 256, 256, 256],\n",
      "                    'input_dim': 18,\n",
      "                    'num_relation': 3,\n",
      "                    'readout': 'sum',\n",
      "                    'short_cut': False},\n",
      "          'reward_temperature': 1.0,\n",
      "          'task': 'plogp'},\n",
      " 'test_set': None,\n",
      " 'train_set': {'atom_feature': 'symbol',\n",
      "               'class': 'datasets.ZINC250k',\n",
      "               'kekulize': True,\n",
      "               'path': './zinc_data',\n",
      "               'verbose': 1},\n",
      " 'valid_set': None}\n",
      "\n",
      " Starting RL fine-tuning...\n",
      "23:56:39   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:56:39   Epoch 0 begin\n",
      "23:56:41   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:56:41   PPO objective: 1.59266\n",
      "23:56:41   Penalized logP: -1.68146\n",
      "23:56:41   Penalized logP (max): 1.55043\n",
      "23:56:57   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:56:57   PPO objective: 1.04842\n",
      "23:56:57   Penalized logP: -2.32175\n",
      "23:56:57   Penalized logP (max): 0.473461\n",
      "23:57:07   1 / 8 molecules are invalid even after 20 resampling\n",
      "23:57:15   1 / 8 molecules are invalid even after 20 resampling\n",
      "23:57:15   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:57:15   PPO objective: 0.896839\n",
      "23:57:15   Penalized logP: -2.92963\n",
      "23:57:15   Penalized logP (max): -1.48814\n",
      "23:57:33   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:57:33   PPO objective: 0.868903\n",
      "23:57:33   Penalized logP: -2.92124\n",
      "23:57:33   Penalized logP (max): -1.61558\n",
      "23:57:51   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:57:51   PPO objective: 1.00609\n",
      "23:57:51   Penalized logP: -2.21023\n",
      "23:57:51   Penalized logP (max): -0.688803\n",
      "23:58:09   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:58:09   PPO objective: 1.00501\n",
      "23:58:09   Penalized logP: -2.87485\n",
      "23:58:09   Penalized logP (max): 0.125554\n",
      "23:58:16   1 / 2 molecules are invalid even after 20 resampling\n",
      "23:58:17   1 / 8 molecules are invalid even after 20 resampling\n",
      "23:58:20   1 / 3 molecules are invalid even after 20 resampling\n",
      "23:58:28   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:58:28   PPO objective: 1.0983\n",
      "23:58:28   Penalized logP: -2.7009\n",
      "23:58:28   Penalized logP (max): 0.750062\n",
      "23:58:45   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:58:45   PPO objective: 1.22449\n",
      "23:58:45   Penalized logP: -2.11093\n",
      "23:58:45   Penalized logP (max): 1.25013\n",
      "23:58:55   1 / 8 molecules are invalid even after 20 resampling\n",
      "23:59:03   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:59:03   PPO objective: 1.18786\n",
      "23:59:03   Penalized logP: -2.24952\n",
      "23:59:03   Penalized logP (max): 0.750062\n",
      "23:59:15   1 / 8 molecules are invalid even after 20 resampling\n",
      "23:59:22   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:59:22   PPO objective: 1.10311\n",
      "23:59:22   Penalized logP: -1.5826\n",
      "23:59:22   Penalized logP (max): 0.322808\n",
      "23:59:42   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:59:42   PPO objective: 1.12988\n",
      "23:59:42   Penalized logP: -2.1297\n",
      "23:59:42   Penalized logP (max): 0.37812\n",
      "23:59:59   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "23:59:59   PPO objective: 0.959421\n",
      "23:59:59   Penalized logP: -2.19345\n",
      "23:59:59   Penalized logP (max): -0.577651\n",
      "00:00:01   1 / 8 molecules are invalid even after 20 resampling\n",
      "00:00:03   1 / 8 molecules are invalid even after 20 resampling\n",
      "00:00:22   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "00:00:22   PPO objective: 0.906179\n",
      "00:00:22   Penalized logP: -2.87509\n",
      "00:00:22   Penalized logP (max): -0.627032\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 235\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# MAIN\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 235\u001b[0m     solver, task \u001b[38;5;241m=\u001b[39m \u001b[43mrun_cn_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimization_goal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     results \u001b[38;5;241m=\u001b[39m generate_molecules(task, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    242\u001b[0m     display_results(results)\n",
      "Cell \u001b[0;32mIn[3], line 189\u001b[0m, in \u001b[0;36mrun_cn_optimization\u001b[0;34m(optimization_goal, target_cn, target_min, target_max, num_epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m    177\u001b[0m solver \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mEngine(\n\u001b[1;32m    178\u001b[0m     task,\n\u001b[1;32m    179\u001b[0m     dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m     log_interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    186\u001b[0m )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Starting RL fine-tuning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m solver\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgcpn_cn_optimized.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Saved: gcpn_cn_optimized.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/core/engine.py:161\u001b[0m, in \u001b[0;36mEngine.train\u001b[0;34m(self, num_epoch, batch_per_epoch)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    159\u001b[0m     batch \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcuda(batch, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 161\u001b[0m loss, metric \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt require grad. Did you define any loss in the task?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/tasks/generation.py:715\u001b[0m, in \u001b[0;36mGCPNGeneration.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    713\u001b[0m     metric\u001b[38;5;241m.\u001b[39mupdate(_metric)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m criterion \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 715\u001b[0m     _loss, _metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreinforce_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    716\u001b[0m     all_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _loss \u001b[38;5;241m*\u001b[39m weight\n\u001b[1;32m    717\u001b[0m     metric\u001b[38;5;241m.\u001b[39mupdate(_metric)\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/tasks/generation.py:819\u001b[0m, in \u001b[0;36mGCPNGeneration.reinforce_forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# generation takes less time when early_stop=True\u001b[39;00m\n\u001b[0;32m--> 819\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgraph\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_resample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moff_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(graph) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnum_nodes\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    821\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeneration results collapse to singleton molecules\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/tasks/generation.py:1350\u001b[0m, in \u001b[0;36mGCPNGeneration.generate\u001b[0;34m(self, num_sample, max_resample, off_policy, max_step, initial_smiles, verbose)\u001b[0m\n\u001b[1;32m   1348\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_step):\n\u001b[0;32m-> 1350\u001b[0m     new_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moff_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_resample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m max_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;66;03m# last step, collect all graph that is valid\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m         result\u001b[38;5;241m.\u001b[39mappend(new_graph[(new_graph\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_node))])            \n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/tasks/generation.py:1203\u001b[0m, in \u001b[0;36mGCPNGeneration._apply_action\u001b[0;34m(self, graph, off_policy, max_resample, verbose, min_node)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     tmp_stop_action, tmp_node1_action, tmp_node2_action, tmp_edge_action \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m   1200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_top1_action(graph, off_policy)\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1202\u001b[0m     tmp_stop_action, tmp_node1_action, tmp_node2_action, tmp_edge_action \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m-> 1203\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moff_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1205\u001b[0m stop_action[mask] \u001b[38;5;241m=\u001b[39m tmp_stop_action[mask]\n\u001b[1;32m   1206\u001b[0m node1_action[mask] \u001b[38;5;241m=\u001b[39m tmp_node1_action[mask]\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/tasks/generation.py:1041\u001b[0m, in \u001b[0;36mGCPNGeneration._sample_action\u001b[0;34m(self, graph, off_policy)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     mlp_edge \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_edge\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;66;03m# step1: get feature\u001b[39;00m\n\u001b[0;32m-> 1041\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_feature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m extended_node2graph \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(graph), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2atom)) \u001b[38;5;66;03m# (num_graph * 16)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m extended_node2graph \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((graph\u001b[38;5;241m.\u001b[39mnode2graph, extended_node2graph)) \u001b[38;5;66;03m# (num_node + 16 * num_graph)\u001b[39;00m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/models/gcn.py:153\u001b[0m, in \u001b[0;36mRelationalGraphConvolutionalNetwork.forward\u001b[0;34m(self, graph, input, all_loss, metric)\u001b[0m\n\u001b[1;32m    150\u001b[0m layer_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 153\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshort_cut \u001b[38;5;129;01mand\u001b[39;00m hidden\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m layer_input\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m    155\u001b[0m         hidden \u001b[38;5;241m=\u001b[39m hidden \u001b[38;5;241m+\u001b[39m layer_input\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/layers/conv.py:91\u001b[0m, in \u001b[0;36mMessagePassingBase.forward\u001b[0;34m(self, graph, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     update \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_and_aggregate, \u001b[38;5;241m*\u001b[39mgraph\u001b[38;5;241m.\u001b[39mto_tensors(), \u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_and_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine(\u001b[38;5;28minput\u001b[39m, update)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/layers/conv.py:422\u001b[0m, in \u001b[0;36mRelationalGraphConv.message_and_aggregate\u001b[0;34m(self, graph, input)\u001b[0m\n\u001b[1;32m    420\u001b[0m degree_out \u001b[38;5;241m=\u001b[39m scatter_add(graph\u001b[38;5;241m.\u001b[39medge_weight, node_out, dim_size\u001b[38;5;241m=\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnum_node \u001b[38;5;241m*\u001b[39m graph\u001b[38;5;241m.\u001b[39mnum_relation)\n\u001b[1;32m    421\u001b[0m edge_weight \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39medge_weight \u001b[38;5;241m/\u001b[39m degree_out[node_out]\n\u001b[0;32m--> 422\u001b[0m adjacency \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_coo_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_out\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_node\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_relation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m update \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mmm(adjacency\u001b[38;5;241m.\u001b[39mt(), \u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_linear:\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/utils/torch.py:185\u001b[0m, in \u001b[0;36msparse_coo_tensor\u001b[0;34m(indices, values, size)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msparse_coo_tensor\u001b[39m(indices, values, size):\n\u001b[1;32m    174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    Construct a sparse COO tensor without index check. Much faster than `torch.sparse_coo_tensor`_.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m        size (list): size of the tensor\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_ext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_coo_tensor_unsafe\u001b[49m(indices, values, size)\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/utils/torch.py:26\u001b[0m, in \u001b[0;36mLazyExtensionLoader.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m, key)\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/utils/decorator.py:102\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 102\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torchdrug/utils/torch.py:30\u001b[0m, in \u001b[0;36mLazyExtensionLoader.module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@decorator\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodule\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcpp_extension\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1306\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(name,\n\u001b[1;32m   1215\u001b[0m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   1216\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1224\u001b[0m          is_standalone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1225\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;124;03m    Load a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;124;03m        ...     verbose=True)\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1669\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1667\u001b[0m with_cudnn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcudnn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m extra_ldflags \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[1;32m   1668\u001b[0m old_version \u001b[38;5;241m=\u001b[39m JIT_EXTENSION_VERSIONER\u001b[38;5;241m.\u001b[39mget_version(name)\n\u001b[0;32m-> 1669\u001b[0m version \u001b[38;5;241m=\u001b[39m \u001b[43mJIT_EXTENSION_VERSIONER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbump_version_if_changed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_arguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m!=\u001b[39m old_version \u001b[38;5;129;01mand\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/utils/_cpp_extension_versioner.py:45\u001b[0m, in \u001b[0;36mExtensionVersioner.bump_version_if_changed\u001b[0;34m(self, name, source_files, build_arguments, build_directory, with_cuda, is_python_module, is_standalone)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbump_version_if_changed\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     37\u001b[0m                             name,\n\u001b[1;32m     38\u001b[0m                             source_files,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m                             is_python_module,\n\u001b[1;32m     43\u001b[0m                             is_standalone):\n\u001b[1;32m     44\u001b[0m     hash_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     hash_value \u001b[38;5;241m=\u001b[39m \u001b[43mhash_source_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhash_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     hash_value \u001b[38;5;241m=\u001b[39m hash_build_arguments(hash_value, build_arguments)\n\u001b[1;32m     47\u001b[0m     hash_value \u001b[38;5;241m=\u001b[39m update_hash(hash_value, build_directory)\n",
      "File \u001b[0;32m~/biofuel-ml/torchdrug_env/lib/python3.10/site-packages/torch/utils/_cpp_extension_versioner.py:15\u001b[0m, in \u001b[0;36mhash_source_files\u001b[0;34m(hash_value, source_files)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhash_source_files\u001b[39m(hash_value, source_files):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m source_files:\n\u001b[0;32m---> 15\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     16\u001b[0m             hash_value \u001b[38;5;241m=\u001b[39m update_hash(hash_value, file\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hash_value\n",
      "File \u001b[0;32m/usr/lib/python3.10/codecs.py:309\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.__init__\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mBufferedIncrementalDecoder\u001b[39;00m(IncrementalDecoder):\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    incremental decoder if the decoder must be able to handle incomplete\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    byte sequences.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    310\u001b[0m         IncrementalDecoder\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors)\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;66;03m# undecoded input that is kept between calls to decode()\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "from torchdrug import core, datasets, models, tasks\n",
    "from torch import optim\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"   # hide GPUs from Torch/TorchDrug\n",
    "\n",
    "# ============================================================\n",
    "# 1. Project paths & imports from src/\n",
    "# ============================================================\n",
    "import joblib\n",
    "import sys, os\n",
    "\n",
    "PROJECT_ROOT = \"/home/salvina2004/biofuel-ml\"\n",
    "SRC_DIR = os.path.join(PROJECT_ROOT, \"src\")\n",
    "\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "sys.path.append(SRC_DIR)\n",
    "\n",
    "print(\"PYTHONPATH updated:\", sys.path)\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "# ============================================================\n",
    "# DEVICE CONFIGURATION\n",
    "# ============================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ============================================================\n",
    "# PROJECT SETUP\n",
    "# ============================================================\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from src.feature_selection import FeatureSelector, prepare_prediction_features\n",
    "from src.feature_engineering import *\n",
    "\n",
    "# Load trained model + selector\n",
    "model = joblib.load(os.path.join(PROJECT_ROOT, \"models/extratrees_model.pkl\"))\n",
    "selector = joblib.load(os.path.join(PROJECT_ROOT, \"models/feature_selector.pkl\"))\n",
    "\n",
    "# ============================================================\n",
    "# CN PREDICTION\n",
    "# ============================================================\n",
    "def predict_cn(smiles: str) -> float:\n",
    "    X = prepare_prediction_features([smiles], selector)\n",
    "    return float(model.predict(X)[0])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# REWARD FUNCTIONS (GPU-SAFE)\n",
    "# ============================================================\n",
    "def reward_maximize_cn(smiles_list, device=device):\n",
    "    rewards = []\n",
    "    for smi in smiles_list:\n",
    "        cn = predict_cn(smi)\n",
    "        rewards.append(min(cn / 120.0, 1.0))\n",
    "    return torch.tensor(rewards, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "def reward_target_range_cn(smiles_list, target_min=50, target_max=70, device=device):\n",
    "    rewards = []\n",
    "    for smi in smiles_list:\n",
    "        cn = predict_cn(smi)\n",
    "        if target_min <= cn <= target_max:\n",
    "            rewards.append(1.0)\n",
    "        else:\n",
    "            d = target_min - cn if cn < target_min else cn - target_max\n",
    "            rewards.append(float(np.exp(-d / 20.0)))\n",
    "    return torch.tensor(rewards, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "def reward_multi_objective(smiles_list, target_cn=60, device=device):\n",
    "    rewards = []\n",
    "    for smi in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol is None:\n",
    "            rewards.append(0.0)\n",
    "            continue\n",
    "\n",
    "        cn = predict_cn(smi)\n",
    "        cn_r = max(0, 1 - abs(cn - target_cn) / 100)\n",
    "\n",
    "        mw = Descriptors.MolWt(mol)\n",
    "        mw_r = 1.0 if 150 < mw < 300 else max(0, 1 - abs(mw - 225) / 200)\n",
    "\n",
    "        logp = Descriptors.MolLogP(mol)\n",
    "        logp_r = 1.0 if 2 < logp < 6 else max(0, 1 - abs(logp - 4) / 5)\n",
    "\n",
    "        rewards.append(0.7 * cn_r + 0.2 * mw_r + 0.1 * logp_r)\n",
    "\n",
    "    return torch.tensor(rewards, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CUSTOM GCPN TASK — REWARD ON GPU\n",
    "# ============================================================\n",
    "class CNOptimizationTask(tasks.GCPNGeneration):\n",
    "    def __init__(self, model, atom_types,\n",
    "                 optimization_goal=\"maximize\",\n",
    "                 target_min=50, target_max=70,\n",
    "                 target_cn=60,\n",
    "                 **kwargs):\n",
    "\n",
    "        super().__init__(model, atom_types, task=\"plogp\", **kwargs)\n",
    "\n",
    "        self.optimization_goal = optimization_goal\n",
    "        self.target_min = target_min\n",
    "        self.target_max = target_max\n",
    "        self.target_cn = target_cn\n",
    "\n",
    "    def get_reward(self, graph, smiles_list):\n",
    "        if self.optimization_goal == \"maximize\":\n",
    "            return reward_maximize_cn(smiles_list, device=device)\n",
    "\n",
    "        elif self.optimization_goal == \"target_range\":\n",
    "            return reward_target_range_cn(smiles_list,\n",
    "                                          target_min=self.target_min,\n",
    "                                          target_max=self.target_max,\n",
    "                                          device=device)\n",
    "\n",
    "        elif self.optimization_goal == \"multi_objective\":\n",
    "            return reward_multi_objective(smiles_list,\n",
    "                                          target_cn=self.target_cn,\n",
    "                                          device=device)\n",
    "\n",
    "        raise ValueError(f\"Unknown reward goal: {self.optimization_goal}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TRAINING PIPELINE (NOW GPU-SAFE)\n",
    "# ============================================================\n",
    "def run_cn_optimization(optimization_goal=\"maximize\",\n",
    "                        target_cn=60,\n",
    "                        target_min=50, target_max=70,\n",
    "                        num_epochs=1,\n",
    "                        batch_size=8,\n",
    "                        lr=1e-5):\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"     CN OPTIMIZATION START    \")\n",
    "    print(\"==============================\")\n",
    "\n",
    "    dataset = datasets.ZINC250k(\"./zinc_data\", kekulize=True, atom_feature=\"symbol\")\n",
    "\n",
    "    gcpn = models.RGCN(\n",
    "        input_dim=dataset.node_feature_dim,\n",
    "        num_relation=dataset.num_bond_type,\n",
    "        hidden_dims=[256, 256, 256, 256],\n",
    "        batch_norm=False\n",
    "    ).to(device)\n",
    "\n",
    "    task = CNOptimizationTask(\n",
    "        gcpn,\n",
    "        dataset.atom_types,\n",
    "        optimization_goal=optimization_goal,\n",
    "        target_cn=target_cn,\n",
    "        target_min=target_min,\n",
    "        target_max=target_max,\n",
    "        max_edge_unroll=12,\n",
    "        max_node=38,\n",
    "        criterion=\"ppo\",\n",
    "        reward_temperature=1.0,\n",
    "        agent_update_interval=3,\n",
    "        gamma=0.9,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(task.parameters(), lr=lr)\n",
    "\n",
    "    solver = core.Engine(\n",
    "        task,\n",
    "        dataset,\n",
    "        None,\n",
    "        None,\n",
    "        optimizer,\n",
    "        gpus=(0,) if torch.cuda.is_available() else None,\n",
    "        batch_size=batch_size,\n",
    "        log_interval=10\n",
    "    )\n",
    "\n",
    "    print(\"\\n Starting RL fine-tuning...\")\n",
    "    solver.train(num_epoch=num_epochs)\n",
    "\n",
    "    solver.save(\"gcpn_cn_optimized.pkl\")\n",
    "    print(\"\\n Saved: gcpn_cn_optimized.pkl\")\n",
    "\n",
    "    return solver, task\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MOLECULE GENERATION\n",
    "# ============================================================\n",
    "def generate_molecules(task, num_samples=20):\n",
    "    task.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        graphs = task.generate(num_sample=num_samples)\n",
    "\n",
    "    results = []\n",
    "    for g in graphs:\n",
    "        smi = g.to_smiles()\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        cn = predict_cn(smi)\n",
    "\n",
    "        results.append({\n",
    "            \"smiles\": smi,\n",
    "            \"cn\": cn,\n",
    "            \"mw\": Descriptors.MolWt(mol) if mol else None,\n",
    "            \"logp\": Descriptors.MolLogP(mol) if mol else None\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def display_results(results, top_k=10):\n",
    "    df = pd.DataFrame(results)\n",
    "    df_sorted = df.sort_values(\"cn\", ascending=False)\n",
    "    print(df_sorted.head(top_k))\n",
    "    df_sorted.to_csv(\"generated_molecules_cn.csv\", index=False)\n",
    "    return df_sorted\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    solver, task = run_cn_optimization(\n",
    "        optimization_goal=\"maximize\",\n",
    "        num_epochs=1,\n",
    "        batch_size=8\n",
    "    )\n",
    "\n",
    "    results = generate_molecules(task, num_samples=10)\n",
    "    display_results(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchdrug_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
